#!/usr/bin/env python3
"""
TESTE COMPLETO - QUALITY FILTERS
Sistema de Recomenda√ß√µes de Investimentos - Fase 2 Passo 2.3

Este script executa uma valida√ß√£o completa do sistema Quality Filters,
verificando se todos os crit√©rios de qualidade est√£o implementados
conforme especificado na Fase 2 Passo 2.3.

FUNCIONALIDADES TESTADAS:
‚úì Filtros de qualidade fundamentalista (ROE>15%, crescimento sustent√°vel, etc.)
‚úì Identifica√ß√£o de red flags em empresas problem√°ticas  
‚úì Sistema de recomenda√ß√µes baseado em crit√©rios objetivos
‚úì An√°lise de consist√™ncia e gera√ß√£o de relat√≥rios
‚úì Sistema de alertas para degrada√ß√£o de qualidade

Data: 14/07/2025
Autor: Claude Sonnet 4
Status: VALIDA√á√ÉO FINAL - Fase 2 Passo 2.3
"""

import sys
import json
import time
import traceback
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

# Setup do projeto
PROJECT_ROOT = Path.cwd()
sys.path.insert(0, str(PROJECT_ROOT))

class TestResult(Enum):
    PASS = "‚úÖ PASS"
    FAIL = "‚ùå FAIL"
    WARN = "‚ö†Ô∏è  WARN"
    INFO = "‚ÑπÔ∏è  INFO"

@dataclass
class TestCase:
    name: str
    description: str
    category: str
    result: Optional[TestResult] = None
    details: str = ""
    score: float = 0.0
    execution_time: float = 0.0

class QualityFiltersValidator:
    """
    Validador completo do Quality Filters
    
    Executa testes abrangentes para verificar se o sistema de
    crit√©rios de qualidade est√° implementado e funcionando corretamente.
    """
    
    def __init__(self):
        self.test_cases: List[TestCase] = []
        self.start_time = datetime.now()
        
        print("üèÜ VALIDA√á√ÉO DO QUALITY FILTERS")
        print("=" * 80)
        print(f"üìÖ Data/Hora: {self.start_time.strftime('%d/%m/%Y %H:%M:%S')}")
        print(f"üìÅ Diret√≥rio: {PROJECT_ROOT}")
        print("üéØ Validando Sistema de Crit√©rios de Qualidade - Fase 2 Passo 2.3")
        print("=" * 80)
    
    def add_test(self, test_case: TestCase):
        """Adiciona um caso de teste"""
        self.test_cases.append(test_case)
    
    def run_test(self, test_func, name: str, description: str, category: str) -> TestCase:
        """Executa um teste e registra o resultado"""
        test_case = TestCase(name=name, description=description, category=category)
        start_time = time.time()
        
        try:
            result, details, score = test_func()
            test_case.result = result
            test_case.details = details
            test_case.score = score
            
        except Exception as e:
            test_case.result = TestResult.FAIL
            test_case.details = f"EXCE√á√ÉO: {str(e)}"
            test_case.score = 0.0
            print(f"‚ùå ERRO CR√çTICO em {name}: {e}")
            traceback.print_exc()
        
        test_case.execution_time = time.time() - start_time
        self.add_test(test_case)
        
        return test_case
    
    # ================================================================
    # TESTES DE ESTRUTURA E IMPORTA√á√ïES
    # ================================================================
    
    def test_file_structure(self) -> Tuple[TestResult, str, float]:
        """Verifica se o arquivo quality_filters.py existe e tem estrutura correta"""
        quality_file = PROJECT_ROOT / "agents" / "analyzers" / "quality_filters.py"
        
        if not quality_file.exists():
            return TestResult.FAIL, "Arquivo quality_filters.py n√£o encontrado", 0.0
        
        try:
            content = quality_file.read_text(encoding='utf-8')
            
            # Verificar componentes essenciais
            required_components = {
                "QualityFiltersEngine": "class QualityFiltersEngine" in content,
                "QualityTier": "class QualityTier" in content,
                "RecommendationType": "class RecommendationType" in content,
                "RedFlag": "class RedFlag" in content or "@dataclass" in content and "RedFlag" in content,
                "QualityFilter": "class QualityFilter" in content or "@dataclass" in content and "QualityFilter" in content,
                "analyze_quality": "def analyze_quality" in content,
                "detect_red_flags": "def _detect_red_flags" in content or "def detect_red_flags" in content,
                "quality_filters": "quality_filters" in content,
                "ROE": "ROE" in content and "15" in content  # Crit√©rio ROE > 15%
            }
            
            found_components = sum(required_components.values())
            total_components = len(required_components)
            
            score = (found_components / total_components) * 20
            
            if found_components == total_components:
                return TestResult.PASS, f"Estrutura completa ({found_components}/{total_components})", score
            elif found_components >= 7:
                missing = [k for k, v in required_components.items() if not v]
                return TestResult.WARN, f"Estrutura quase completa - Faltam: {missing}", score
            else:
                return TestResult.FAIL, f"Estrutura incompleta ({found_components}/{total_components})", score
                
        except Exception as e:
            return TestResult.FAIL, f"Erro ao ler arquivo: {e}", 0.0
    
    def test_imports_and_classes(self) -> Tuple[TestResult, str, float]:
        """Testa se todas as importa√ß√µes e classes est√£o funcionando"""
        try:
            # Tentar importar o m√≥dulo principal
            sys.path.append(str(PROJECT_ROOT / "agents" / "analyzers"))
            
            from quality_filters import (
                QualityFiltersEngine,
                QualityTier,
                RecommendationType,
                create_quality_filters_engine
            )
            
            # Verificar se pode criar inst√¢ncia
            engine = create_quality_filters_engine()
            
            # Verificar m√©todos principais
            required_methods = [
                'analyze_quality',
                'batch_analyze',
                'get_quality_summary'
            ]
            
            missing_methods = []
            for method in required_methods:
                if not hasattr(engine, method):
                    missing_methods.append(method)
            
            # Verificar enums
            quality_tiers = list(QualityTier)
            recommendations = list(RecommendationType)
            
            if not missing_methods and len(quality_tiers) >= 4 and len(recommendations) >= 4:
                return TestResult.PASS, "Todas as importa√ß√µes e classes funcionando", 20.0
            else:
                issues = []
                if missing_methods:
                    issues.append(f"M√©todos faltantes: {missing_methods}")
                if len(quality_tiers) < 4:
                    issues.append(f"QualityTier incompleto ({len(quality_tiers)} tiers)")
                if len(recommendations) < 4:
                    issues.append(f"RecommendationType incompleto ({len(recommendations)} tipos)")
                
                return TestResult.WARN, f"Problemas: {'; '.join(issues)}", 15.0
                
        except ImportError as e:
            return TestResult.FAIL, f"Erro de importa√ß√£o: {e}", 0.0
        except Exception as e:
            return TestResult.FAIL, f"Erro inesperado: {e}", 0.0
    
    # ================================================================
    # TESTES DE FILTROS DE QUALIDADE
    # ================================================================
    
    def test_quality_filters_implementation(self) -> Tuple[TestResult, str, float]:
        """Testa implementa√ß√£o dos filtros de qualidade obrigat√≥rios"""
        try:
            from quality_filters import create_quality_filters_engine, get_quality_filters_list
            
            engine = create_quality_filters_engine()
            filters_list = get_quality_filters_list()
            
            # Verificar filtros obrigat√≥rios conforme especifica√ß√£o
            required_filters = {
                'ROE': False,
                'crescimento': False,
                'endividamento': False,
                'margem': False
            }
            
            for filter_info in filters_list:
                filter_name = filter_info['name'].lower()
                filter_desc = filter_info['description'].lower()
                
                # ROE consistente > 15%
                if 'roe' in filter_name or 'roe' in filter_desc:
                    if filter_info['threshold'] >= 15.0:
                        required_filters['ROE'] = True
                
                # Crescimento sustent√°vel
                if 'crescimento' in filter_desc or 'growth' in filter_desc or 'revenue' in filter_info['metric']:
                    required_filters['crescimento'] = True
                
                # Endividamento controlado
                if 'debt' in filter_info['metric'] or 'endiv' in filter_desc:
                    required_filters['endividamento'] = True
                
                # Margens est√°veis
                if 'margin' in filter_info['metric'] or 'margem' in filter_desc:
                    required_filters['margem'] = True
            
            implemented_filters = sum(required_filters.values())
            total_required = len(required_filters)
            
            score = (implemented_filters / total_required) * 20
            
            if implemented_filters == total_required:
                return TestResult.PASS, f"Todos os filtros obrigat√≥rios implementados ({implemented_filters}/{total_required})", score
            elif implemented_filters >= 3:
                missing = [k for k, v in required_filters.items() if not v]
                return TestResult.WARN, f"Filtros principais implementados - Faltam: {missing}", score
            else:
                return TestResult.FAIL, f"Filtros insuficientes ({implemented_filters}/{total_required})", score
                
        except Exception as e:
            return TestResult.FAIL, f"Erro no teste de filtros: {e}", 0.0
    
    def test_quality_analysis_functionality(self) -> Tuple[TestResult, str, float]:
        """Testa funcionalidade de an√°lise de qualidade"""
        try:
            from quality_filters import create_quality_filters_engine, QualityTier
            
            engine = create_quality_filters_engine()
            
            # Dados de teste - empresa de alta qualidade
            high_quality_metrics = {
                'roe': 20.0,          # > 15% ‚úì
                'roa': 8.0,
                'roic': 15.0,
                'revenue_growth_3y': 10.0,  # Crescimento sustent√°vel ‚úì
                'debt_ebitda': 2.0,    # Endividamento controlado ‚úì
                'current_ratio': 1.8,
                'net_margin': 12.0,    # Margem est√°vel ‚úì
                'ebitda_margin': 20.0,
                'pe_ratio': 18.0
            }
            
            # Executar an√°lise
            analysis = engine.analyze_quality("TEST_GOOD", high_quality_metrics)
            
            # Valida√ß√µes
            validations = [
                analysis.stock_code == "TEST_GOOD",
                analysis.quality_score > 60.0,  # Deveria ser alta
                analysis.quality_tier in [QualityTier.GOOD, QualityTier.EXCELLENT],
                analysis.filters_passed > analysis.total_filters * 0.7,  # Pelo menos 70% dos filtros
                len(analysis.red_flags) <= 2,  # Poucos red flags
                analysis.critical_red_flags == 0  # Nenhum red flag cr√≠tico
            ]
            
            passed_validations = sum(validations)
            
            if passed_validations >= 5:
                return TestResult.PASS, f"An√°lise funcionando corretamente ({passed_validations}/6 valida√ß√µes)", 20.0
            elif passed_validations >= 4:
                return TestResult.WARN, f"An√°lise funcional com limita√ß√µes ({passed_validations}/6)", 15.0
            else:
                details = f"Score: {analysis.quality_score:.1f}, Tier: {analysis.quality_tier}, Filtros: {analysis.filters_passed}/{analysis.total_filters}"
                return TestResult.FAIL, f"An√°lise com problemas ({passed_validations}/6) - {details}", 8.0
                
        except Exception as e:
            return TestResult.FAIL, f"Erro na an√°lise de qualidade: {e}", 0.0
    
    # ================================================================
    # TESTES DE RED FLAGS
    # ================================================================
    
    def test_red_flags_detection(self) -> Tuple[TestResult, str, float]:
        """Testa detec√ß√£o de red flags cr√≠ticos"""
        try:
            from quality_filters import create_quality_filters_engine, RedFlagSeverity
            
            engine = create_quality_filters_engine()
            
            # Dados de teste - empresa com m√∫ltiplos red flags
            problematic_metrics = {
                'roe': -5.0,           # Red flag cr√≠tico
                'roa': 1.0,
                'revenue_growth_3y': -15.0,  # Red flag alto
                'debt_ebitda': 8.0,    # Red flag cr√≠tico
                'current_ratio': 0.8,  # Red flag alto
                'net_margin': -3.0,    # Red flag cr√≠tico
                'ebitda_margin': 5.0,
                'pe_ratio': 50.0       # Red flag m√©dio
            }
            
            # Executar an√°lise
            analysis = engine.analyze_quality("TEST_BAD", problematic_metrics)
            
            # Valida√ß√µes espec√≠ficas para red flags
            critical_flags = [rf for rf in analysis.red_flags if hasattr(rf, 'severity') and rf.severity.name == 'CRITICAL']
            high_flags = [rf for rf in analysis.red_flags if hasattr(rf, 'severity') and rf.severity.name == 'HIGH']
            
            validations = [
                len(analysis.red_flags) >= 3,  # Deve detectar m√∫ltiplos red flags
                len(critical_flags) >= 2,      # Pelo menos 2 cr√≠ticos (ROE negativo, d√≠vida alta, margem negativa)
                analysis.quality_score < 40.0,  # Score deve ser baixo
                analysis.critical_red_flags > 0,  # Contador de cr√≠ticos
                len(analysis.weaknesses) > len(analysis.strengths),  # Mais fraquezas que for√ßas
                'VENDA' in analysis.recommendation.value  # Recomenda√ß√£o de venda
            ]
            
            passed_validations = sum(validations)
            
            details = f"Red flags: {len(analysis.red_flags)} (cr√≠ticos: {len(critical_flags)}), Score: {analysis.quality_score:.1f}"
            
            if passed_validations >= 5:
                return TestResult.PASS, f"Detec√ß√£o de red flags funcionando - {details}", 20.0
            elif passed_validations >= 4:
                return TestResult.WARN, f"Detec√ß√£o parcial - {details}", 15.0
            else:
                return TestResult.FAIL, f"Detec√ß√£o insuficiente ({passed_validations}/6) - {details}", 8.0
                
        except Exception as e:
            return TestResult.FAIL, f"Erro na detec√ß√£o de red flags: {e}", 0.0
    
    def test_red_flags_types(self) -> Tuple[TestResult, str, float]:
        """Testa tipos espec√≠ficos de red flags conforme especifica√ß√£o"""
        try:
            from quality_filters import get_red_flag_types
            
            red_flag_types = get_red_flag_types()
            
            # Red flags obrigat√≥rios conforme especifica√ß√£o
            required_red_flags = {
                'roe_negativo': False,
                'endividamento_excessivo': False,
                'margem_negativa': False,
                'queda_receita': False
            }
            
            for rf_type in red_flag_types:
                rf_name = rf_type['name'].lower()
                rf_desc = rf_type['description'].lower()
                
                # ROE negativo
                if 'roe' in rf_name and ('negativ' in rf_name or 'negativ' in rf_desc):
                    required_red_flags['roe_negativo'] = True
                
                # Endividamento excessivo
                if ('endiv' in rf_name or 'debt' in rf_name) and ('excess' in rf_desc or 'excess' in rf_name):
                    required_red_flags['endividamento_excessivo'] = True
                
                # Margem negativa
                if 'margin' in rf_name and ('negativ' in rf_desc or 'negativ' in rf_name):
                    required_red_flags['margem_negativa'] = True
                
                # Queda de receita
                if ('receita' in rf_desc or 'revenue' in rf_name) and ('queda' in rf_desc or 'growth' in rf_name):
                    required_red_flags['queda_receita'] = True
            
            implemented_flags = sum(required_red_flags.values())
            total_required = len(required_red_flags)
            
            score = (implemented_flags / total_required) * 15
            
            if implemented_flags == total_required:
                return TestResult.PASS, f"Todos os red flags obrigat√≥rios implementados ({implemented_flags}/{total_required})", score
            elif implemented_flags >= 3:
                missing = [k for k, v in required_red_flags.items() if not v]
                return TestResult.WARN, f"Red flags principais implementados - Faltam: {missing}", score
            else:
                return TestResult.FAIL, f"Red flags insuficientes ({implemented_flags}/{total_required})", score
                
        except Exception as e:
            return TestResult.FAIL, f"Erro no teste de tipos de red flags: {e}", 0.0
    
    # ================================================================
    # TESTES DE SISTEMA DE RECOMENDA√á√ïES
    # ================================================================
    
    def test_recommendation_system(self) -> Tuple[TestResult, str, float]:
        """Testa sistema de recomenda√ß√µes baseado em crit√©rios"""
        try:
            from quality_filters import create_quality_filters_engine, RecommendationType
            
            engine = create_quality_filters_engine()
            
            # Cen√°rio 1: Empresa excelente - deve recomendar COMPRA
            excellent_metrics = {
                'roe': 25.0, 'roa': 12.0, 'roic': 18.0,
                'revenue_growth_3y': 15.0, 'debt_ebitda': 1.5,
                'current_ratio': 2.0, 'net_margin': 18.0,
                'ebitda_margin': 25.0, 'pe_ratio': 15.0
            }
            
            # Cen√°rio 2: Empresa m√©dia - deve recomendar MANTER
            average_metrics = {
                'roe': 12.0, 'roa': 6.0, 'roic': 10.0,
                'revenue_growth_3y': 3.0, 'debt_ebitda': 3.5,
                'current_ratio': 1.3, 'net_margin': 8.0,
                'ebitda_margin': 15.0, 'pe_ratio': 22.0
            }
            
            # Cen√°rio 3: Empresa problem√°tica - deve recomendar VENDA
            poor_metrics = {
                'roe': -2.0, 'roa': 1.0, 'roic': 2.0,
                'revenue_growth_3y': -10.0, 'debt_ebitda': 7.0,
                'current_ratio': 0.9, 'net_margin': -1.0,
                'ebitda_margin': 8.0, 'pe_ratio': 40.0
            }
            
            # Executar an√°lises
            excellent_analysis = engine.analyze_quality("EXCELLENT", excellent_metrics)
            average_analysis = engine.analyze_quality("AVERAGE", average_metrics)
            poor_analysis = engine.analyze_quality("POOR", poor_metrics)
            
            # Validar recomenda√ß√µes
            validations = [
                excellent_analysis.recommendation in [RecommendationType.BUY, RecommendationType.STRONG_BUY],
                excellent_analysis.confidence > 70.0,
                average_analysis.recommendation in [RecommendationType.HOLD, RecommendationType.BUY],
                poor_analysis.recommendation in [RecommendationType.SELL, RecommendationType.STRONG_SELL],
                poor_analysis.confidence > 60.0,
                excellent_analysis.quality_score > average_analysis.quality_score > poor_analysis.quality_score
            ]
            
            passed_validations = sum(validations)
            
            details = f"Excellent: {excellent_analysis.recommendation.value} ({excellent_analysis.confidence:.0f}%), "
            details += f"Average: {average_analysis.recommendation.value}, "
            details += f"Poor: {poor_analysis.recommendation.value} ({poor_analysis.confidence:.0f}%)"
            
            if passed_validations >= 5:
                return TestResult.PASS, f"Sistema de recomenda√ß√µes funcionando - {details}", 20.0
            elif passed_validations >= 4:
                return TestResult.WARN, f"Recomenda√ß√µes parciais - {details}", 15.0
            else:
                return TestResult.FAIL, f"Problemas nas recomenda√ß√µes ({passed_validations}/6) - {details}", 8.0
                
        except Exception as e:
            return TestResult.FAIL, f"Erro no sistema de recomenda√ß√µes: {e}", 0.0
    
    def test_confidence_calculation(self) -> Tuple[TestResult, str, float]:
        """Testa c√°lculo de confidence nas recomenda√ß√µes"""
        try:
            from quality_filters import create_quality_filters_engine
            
            engine = create_quality_filters_engine()
            
            # Dados de teste com diferentes n√≠veis de qualidade
            test_cases = [
                {'metrics': {'roe': 30.0, 'debt_ebitda': 1.0, 'net_margin': 20.0, 'revenue_growth_3y': 20.0}, 'expected_confidence': 80.0},
                {'metrics': {'roe': 15.0, 'debt_ebitda': 3.0, 'net_margin': 10.0, 'revenue_growth_3y': 5.0}, 'expected_confidence': 50.0},
                {'metrics': {'roe': -5.0, 'debt_ebitda': 8.0, 'net_margin': -2.0, 'revenue_growth_3y': -15.0}, 'expected_confidence': 70.0}
            ]
            
            confidence_tests = []
            
            for i, test_case in enumerate(test_cases):
                analysis = engine.analyze_quality(f"TEST_{i}", test_case['metrics'])
                
                # Confidence deve estar no range v√°lido e fazer sentido
                valid_confidence = (
                    0.0 <= analysis.confidence <= 100.0 and
                    analysis.confidence > 30.0  # M√≠nimo de confidence para qualquer recomenda√ß√£o
                )
                
                confidence_tests.append(valid_confidence)
            
            passed_tests = sum(confidence_tests)
            
            if passed_tests == len(test_cases):
                return TestResult.PASS, f"C√°lculo de confidence funcionando ({passed_tests}/{len(test_cases)})", 10.0
            elif passed_tests >= 2:
                return TestResult.WARN, f"Confidence parcialmente funcional ({passed_tests}/{len(test_cases)})", 7.0
            else:
                return TestResult.FAIL, f"Problemas no c√°lculo de confidence ({passed_tests}/{len(test_cases)})", 3.0
                
        except Exception as e:
            return TestResult.FAIL, f"Erro no teste de confidence: {e}", 0.0
    
    # ================================================================
    # TESTES DE FUNCIONALIDADES AVAN√áADAS
    # ================================================================
    
    def test_batch_processing(self) -> Tuple[TestResult, str, float]:
        """Testa processamento em lote"""
        try:
            from quality_filters import create_quality_filters_engine
            
            engine = create_quality_filters_engine()
            
            # Dados de teste para processamento em lote
            batch_data = [
                {
                    'stock_code': 'BATCH1',
                    'metrics': {'roe': 20.0, 'debt_ebitda': 2.0, 'net_margin': 15.0, 'revenue_growth_3y': 10.0}
                },
                {
                    'stock_code': 'BATCH2', 
                    'metrics': {'roe': 10.0, 'debt_ebitda': 4.0, 'net_margin': 5.0, 'revenue_growth_3y': 2.0}
                },
                {
                    'stock_code': 'BATCH3',
                    'metrics': {'roe': -5.0, 'debt_ebitda': 8.0, 'net_margin': -2.0, 'revenue_growth_3y': -10.0}
                }
            ]
            
            # Executar processamento em lote
            batch_results = engine.batch_analyze(batch_data)
            
            # Valida√ß√µes
            validations = [
                len(batch_results) == len(batch_data),
                all(hasattr(result, 'stock_code') for result in batch_results),
                all(hasattr(result, 'quality_score') for result in batch_results),
                all(hasattr(result, 'recommendation') for result in batch_results),
                len(set(r.stock_code for r in batch_results)) == 3  # C√≥digos √∫nicos
            ]
            
            passed_validations = sum(validations)
            
            if passed_validations == 5:
                return TestResult.PASS, f"Processamento em lote funcionando ({len(batch_results)} empresas)", 15.0
            elif passed_validations >= 4:
                return TestResult.WARN, f"Batch parcial ({passed_validations}/5 valida√ß√µes)", 10.0
            else:
                return TestResult.FAIL, f"Problemas no batch ({passed_validations}/5)", 5.0
                
        except Exception as e:
            return TestResult.FAIL, f"Erro no processamento em lote: {e}", 0.0
    
    def test_quality_summary(self) -> Tuple[TestResult, str, float]:
        """Testa gera√ß√£o de resumo de qualidade"""
        try:
            from quality_filters import create_quality_filters_engine
            
            engine = create_quality_filters_engine()
            
            # Criar an√°lises de teste
            test_data = [
                {'stock_code': 'GOOD1', 'metrics': {'roe': 25.0, 'debt_ebitda': 1.5, 'net_margin': 18.0}},
                {'stock_code': 'GOOD2', 'metrics': {'roe': 22.0, 'debt_ebitda': 2.0, 'net_margin': 15.0}},
                {'stock_code': 'AVG1', 'metrics': {'roe': 12.0, 'debt_ebitda': 3.5, 'net_margin': 8.0}},
                {'stock_code': 'POOR1', 'metrics': {'roe': -2.0, 'debt_ebitda': 7.0, 'net_margin': -1.0}}
            ]
            
            analyses = engine.batch_analyze(test_data)
            summary = engine.get_quality_summary(analyses)
            
            # Verificar campos essenciais do resumo
            required_fields = [
                'total_analyzed',
                'average_quality_score',
                'tier_distribution',
                'recommendation_distribution',
                'companies_with_red_flags'
            ]
            
            fields_present = sum(1 for field in required_fields if field in summary)
            
            # Valida√ß√µes adicionais
            valid_stats = (
                summary.get('total_analyzed', 0) == 4 and
                isinstance(summary.get('average_quality_score', 0), (int, float)) and
                isinstance(summary.get('tier_distribution', {}), dict) and
                isinstance(summary.get('recommendation_distribution', {}), dict)
            )
            
            if fields_present == len(required_fields) and valid_stats:
                return TestResult.PASS, f"Resumo de qualidade completo ({fields_present}/{len(required_fields)} campos)", 15.0
            elif fields_present >= 4:
                return TestResult.WARN, f"Resumo parcial ({fields_present}/{len(required_fields)})", 10.0
            else:
                return TestResult.FAIL, f"Resumo incompleto ({fields_present}/{len(required_fields)})", 5.0
                
        except Exception as e:
            return TestResult.FAIL, f"Erro no resumo de qualidade: {e}", 0.0
    
    def test_utility_functions(self) -> Tuple[TestResult, str, float]:
        """Testa fun√ß√µes utilit√°rias"""
        try:
            from quality_filters import (
                quick_quality_check,
                get_quality_filters_list,
                get_red_flag_types
            )
            
            # Teste quick_quality_check
            test_metrics = {'roe': 18.0, 'debt_ebitda': 2.5, 'net_margin': 12.0}
            quick_result = quick_quality_check("QUICK_TEST", test_metrics)
            
            # Teste get_quality_filters_list
            filters_list = get_quality_filters_list()
            
            # Teste get_red_flag_types
            red_flags_list = get_red_flag_types()
            
            # Valida√ß√µes
            validations = [
                isinstance(quick_result, dict) and 'quality_score' in quick_result,
                isinstance(filters_list, list) and len(filters_list) > 5,
                isinstance(red_flags_list, list) and len(red_flags_list) > 5,
                'recommendation' in quick_result and 'confidence' in quick_result,
                all('name' in f and 'threshold' in f for f in filters_list),
                all('name' in rf and 'severity' in rf for rf in red_flags_list)
            ]
            
            passed_validations = sum(validations)
            
            details = f"Quick check: OK, Filtros: {len(filters_list)}, Red flags: {len(red_flags_list)}"
            
            if passed_validations == 6:
                return TestResult.PASS, f"Fun√ß√µes utilit√°rias funcionando - {details}", 10.0
            elif passed_validations >= 4:
                return TestResult.WARN, f"Utilidades parciais ({passed_validations}/6) - {details}", 7.0
            else:
                return TestResult.FAIL, f"Problemas nas utilidades ({passed_validations}/6)", 3.0
                
        except Exception as e:
            return TestResult.FAIL, f"Erro nas fun√ß√µes utilit√°rias: {e}", 0.0
    
    def test_alerting_system(self) -> Tuple[TestResult, str, float]:
        """Testa sistema de alertas para degrada√ß√£o"""
        try:
            from quality_filters import create_quality_filters_engine, QualityAlert, QualityTier, RecommendationType
            
            # Criar an√°lises simuladas
            engine = create_quality_filters_engine()
            
            # An√°lise anterior (boa qualidade)
            previous_metrics = {'roe': 20.0, 'debt_ebitda': 2.0, 'net_margin': 15.0, 'revenue_growth_3y': 10.0}
            previous_analysis = engine.analyze_quality("TEST_DEGRADATION", previous_metrics)
            
            # An√°lise atual (qualidade degradada)
            current_metrics = {'roe': -5.0, 'debt_ebitda': 8.0, 'net_margin': -2.0, 'revenue_growth_3y': -15.0}
            current_analysis = engine.analyze_quality("TEST_DEGRADATION", current_metrics)
            
            # Testar sistema de alertas
            alert_system = QualityAlert()
            alerts = alert_system.check_quality_degradation(previous_analysis, current_analysis)
            
            # Valida√ß√µes
            validations = [
                len(alerts) > 0,  # Deve detectar alertas
                any('queda' in alert.lower() or 'drop' in alert.lower() for alert in alerts),  # Alerta de queda de score
                any('red flag' in alert.lower() for alert in alerts),  # Alerta de novos red flags
                any('downgrade' in alert.lower() for alert in alerts),  # Alerta de downgrade
                isinstance(alerts, list),
                all(isinstance(alert, str) for alert in alerts)
            ]
            
            passed_validations = sum(validations)
            
            if passed_validations >= 5:
                return TestResult.PASS, f"Sistema de alertas funcionando ({len(alerts)} alertas detectados)", 10.0
            elif passed_validations >= 3:
                return TestResult.WARN, f"Alertas parciais ({passed_validations}/6)", 7.0
            else:
                return TestResult.FAIL, f"Problemas no sistema de alertas ({passed_validations}/6)", 3.0
                
        except Exception as e:
            return TestResult.FAIL, f"Erro no teste de alertas: {e}", 0.0
    
    def test_report_generation(self) -> Tuple[TestResult, str, float]:
        """Testa gera√ß√£o de relat√≥rios detalhados"""
        try:
            from quality_filters import create_quality_filters_engine, QualityReportGenerator
            
            engine = create_quality_filters_engine()
            
            # Criar an√°lise de teste
            test_metrics = {'roe': 18.0, 'debt_ebitda': 2.5, 'net_margin': 12.0, 'revenue_growth_3y': 8.0}
            analysis = engine.analyze_quality("REPORT_TEST", test_metrics)
            
            # Testar gerador de relat√≥rios
            report_gen = QualityReportGenerator()
            
            # Relat√≥rio de empresa individual
            company_report = report_gen.generate_company_report(analysis)
            
            # Relat√≥rio de portf√≥lio
            portfolio_report = report_gen.generate_portfolio_report([analysis])
            
            # Valida√ß√µes do relat√≥rio de empresa
            company_validations = [
                'company_info' in company_report,
                'quality_assessment' in company_report,
                'red_flags' in company_report,
                'strengths' in company_report,
                'weaknesses' in company_report,
                'summary' in company_report
            ]
            
            # Valida√ß√µes do relat√≥rio de portf√≥lio
            portfolio_validations = [
                'portfolio_summary' in portfolio_report,
                'top_performers' in portfolio_report,
                'bottom_performers' in portfolio_report,
                'report_metadata' in portfolio_report
            ]
            
            company_score = sum(company_validations)
            portfolio_score = sum(portfolio_validations)
            total_validations = company_score + portfolio_score
            max_validations = len(company_validations) + len(portfolio_validations)
            
            if total_validations >= 9:
                return TestResult.PASS, f"Relat√≥rios completos ({total_validations}/{max_validations})", 15.0
            elif total_validations >= 7:
                return TestResult.WARN, f"Relat√≥rios parciais ({total_validations}/{max_validations})", 10.0
            else:
                return TestResult.FAIL, f"Relat√≥rios incompletos ({total_validations}/{max_validations})", 5.0
                
        except Exception as e:
            return TestResult.FAIL, f"Erro na gera√ß√£o de relat√≥rios: {e}", 0.0
    
    # ================================================================
    # RELAT√ìRIO FINAL
    # ================================================================
    
    def generate_final_report(self) -> Dict[str, Any]:
        """Gera relat√≥rio final da valida√ß√£o"""
        total_tests = len(self.test_cases)
        passed_tests = len([t for t in self.test_cases if t.result == TestResult.PASS])
        failed_tests = len([t for t in self.test_cases if t.result == TestResult.FAIL])
        warned_tests = len([t for t in self.test_cases if t.result == TestResult.WARN])
        
        total_score = sum(t.score for t in self.test_cases)
        max_possible_score = 195.0  # Total m√°ximo baseado nos testes
        
        success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        score_percentage = (total_score / max_possible_score * 100) if max_possible_score > 0 else 0
        
        # Determinar status final
        if success_rate >= 85 and score_percentage >= 80:
            final_status = "‚úÖ COMPLETO"
        elif success_rate >= 70 and score_percentage >= 70:
            final_status = "‚ö†Ô∏è  FUNCIONAL"
        elif success_rate >= 50 and score_percentage >= 50:
            final_status = "üîß PARCIAL"
        else:
            final_status = "‚ùå INCOMPLETO"
        
        execution_time = datetime.now() - self.start_time
        
        return {
            'validation_summary': {
                'status': final_status,
                'success_rate': success_rate,
                'score_percentage': score_percentage,
                'execution_time': str(execution_time).split('.')[0]
            },
            'test_results': {
                'total_tests': total_tests,
                'passed': passed_tests,
                'failed': failed_tests,
                'warnings': warned_tests
            },
            'score_breakdown': {
                'total_score': total_score,
                'max_possible': max_possible_score,
                'percentage': score_percentage
            }
        }


def main():
    """Fun√ß√£o principal - executa valida√ß√£o completa"""
    print("üèÜ VALIDA√á√ÉO COMPLETA DO QUALITY FILTERS")
    print("=" * 80)
    print("Testando Fase 2 Passo 2.3 - Sistema de Crit√©rios de Qualidade")
    print("=" * 80)
    
    validator = QualityFiltersValidator()
    
    # Lista de testes a executar
    test_suite = [
        (validator.test_file_structure, "Estrutura do Arquivo", "Verifica arquivo e componentes essenciais", "Estrutura"),
        (validator.test_imports_and_classes, "Importa√ß√µes e Classes", "Testa importa√ß√µes e cria√ß√£o de objetos", "Estrutura"),
        (validator.test_quality_filters_implementation, "Filtros de Qualidade", "Valida implementa√ß√£o dos filtros obrigat√≥rios", "Core"),
        (validator.test_quality_analysis_functionality, "An√°lise de Qualidade", "Testa funcionalidade principal de an√°lise", "Core"),
        (validator.test_red_flags_detection, "Detec√ß√£o de Red Flags", "Valida detec√ß√£o de problemas cr√≠ticos", "Core"),
        (validator.test_red_flags_types, "Tipos de Red Flags", "Verifica red flags obrigat√≥rios", "Core"),
        (validator.test_recommendation_system, "Sistema de Recomenda√ß√µes", "Testa gera√ß√£o de recomenda√ß√µes", "Recomenda√ß√µes"),
        (validator.test_confidence_calculation, "C√°lculo de Confidence", "Valida c√°lculo de confian√ßa", "Recomenda√ß√µes"),
        (validator.test_batch_processing, "Processamento em Lote", "Testa an√°lise de m√∫ltiplas empresas", "Performance"),
        (validator.test_quality_summary, "Resumo de Qualidade", "Valida gera√ß√£o de estat√≠sticas", "Relat√≥rios"),
        (validator.test_utility_functions, "Fun√ß√µes Utilit√°rias", "Testa fun√ß√µes de conveni√™ncia", "Utilidades"),
        (validator.test_alerting_system, "Sistema de Alertas", "Valida alertas de degrada√ß√£o", "Monitoramento"),
        (validator.test_report_generation, "Gera√ß√£o de Relat√≥rios", "Testa cria√ß√£o de relat√≥rios detalhados", "Relat√≥rios")
    ]
    
    print(f"\nüß™ Executando {len(test_suite)} testes...\n")
    
    # Executar todos os testes
    for i, (test_func, name, description, category) in enumerate(test_suite, 1):
        print(f"[{i:2d}/{len(test_suite)}] üß™ {name}")
        print(f"        üìù {description}")
        
        test_case = validator.run_test(test_func, name, description, category)
        
        # Exibir resultado imediato
        result_icon = {
            TestResult.PASS: "‚úÖ",
            TestResult.WARN: "‚ö†Ô∏è",
            TestResult.FAIL: "‚ùå",
            TestResult.INFO: "‚ÑπÔ∏è"
        }.get(test_case.result, "‚ùì")
        
        print(f"        {result_icon} {test_case.result.value} - {test_case.details}")
        print(f"        üéØ Score: {test_case.score:.1f} | ‚è±Ô∏è  Tempo: {test_case.execution_time:.3f}s")
        print()
    
    # Gerar relat√≥rio final
    print("=" * 80)
    print("üìä RELAT√ìRIO FINAL - QUALITY FILTERS VALIDATION")
    print("=" * 80)
    
    report = validator.generate_final_report()
    
    # Resumo executivo
    summary = report['validation_summary']
    print(f"\nüéØ STATUS FINAL: {summary['status']}")
    print(f"üìà Taxa de Sucesso: {summary['success_rate']:.1f}%")
    print(f"üéØ Score Total: {summary['score_percentage']:.1f}%")
    print(f"‚è±Ô∏è  Tempo Total: {summary['execution_time']}")
    
    # Breakdown de resultados
    results = report['test_results']
    print(f"\nüìä RESULTADOS DETALHADOS:")
    print(f"   ‚úÖ Testes Passaram: {results['passed']}")
    print(f"   ‚ö†Ô∏è  Testes com Aviso: {results['warnings']}")
    print(f"   ‚ùå Testes Falharam: {results['failed']}")
    print(f"   üìù Total de Testes: {results['total_tests']}")
    
    # Score breakdown
    scores = report['score_breakdown']
    print(f"\nüéØ PONTUA√á√ÉO:")
    print(f"   Score Obtido: {scores['total_score']:.1f}")
    print(f"   Score M√°ximo: {scores['max_possible']:.1f}")
    print(f"   Percentual: {scores['percentage']:.1f}%")
    
    # Testes por categoria
    print(f"\nüìÇ RESULTADOS POR CATEGORIA:")
    categories = {}
    for test in validator.test_cases:
        if test.category not in categories:
            categories[test.category] = {'passed': 0, 'total': 0, 'score': 0}
        categories[test.category]['total'] += 1
        categories[test.category]['score'] += test.score
        if test.result == TestResult.PASS:
            categories[test.category]['passed'] += 1
    
    for category, stats in categories.items():
        rate = (stats['passed'] / stats['total'] * 100) if stats['total'] > 0 else 0
        print(f"   {category}: {stats['passed']}/{stats['total']} ({rate:.0f}%) - Score: {stats['score']:.1f}")
    
    # Funcionalidades validadas
    print(f"\n‚úÖ FUNCIONALIDADES VALIDADAS:")
    
    functionality_status = {
        "Filtros de qualidade fundamentalista": any(t.name == "Filtros de Qualidade" and t.result == TestResult.PASS for t in validator.test_cases),
        "ROE consistente > 15%": any("ROE" in t.details and t.result == TestResult.PASS for t in validator.test_cases),
        "Crescimento sustent√°vel": any("crescimento" in t.details.lower() and t.result == TestResult.PASS for t in validator.test_cases),
        "Endividamento controlado": any("endividamento" in t.details.lower() and t.result == TestResult.PASS for t in validator.test_cases),
        "Margens est√°veis": any("margem" in t.details.lower() and t.result == TestResult.PASS for t in validator.test_cases),
        "Red flags cr√≠ticos": any(t.name == "Detec√ß√£o de Red Flags" and t.result == TestResult.PASS for t in validator.test_cases),
        "Sistema de recomenda√ß√µes": any(t.name == "Sistema de Recomenda√ß√µes" and t.result == TestResult.PASS for t in validator.test_cases),
        "Processamento em lote": any(t.name == "Processamento em Lote" and t.result == TestResult.PASS for t in validator.test_cases),
        "An√°lise de confidence": any(t.name == "C√°lculo de Confidence" and t.result == TestResult.PASS for t in validator.test_cases),
        "Resumos estat√≠sticos": any(t.name == "Resumo de Qualidade" and t.result == TestResult.PASS for t in validator.test_cases),
        "Sistema de alertas": any(t.name == "Sistema de Alertas" and t.result == TestResult.PASS for t in validator.test_cases),
        "Gera√ß√£o de relat√≥rios": any(t.name == "Gera√ß√£o de Relat√≥rios" and t.result == TestResult.PASS for t in validator.test_cases)
    }
    
    for functionality, status in functionality_status.items():
        icon = "‚úÖ" if status else "‚ùå"
        print(f"   {icon} {functionality}")
    
    # Status da Fase 2 Passo 2.3
    overall_success = summary['score_percentage'] >= 70
    
    print(f"\nüéØ FASE 2 PASSO 2.3 - SISTEMA DE CRIT√âRIOS DE QUALIDADE:")
    if overall_success:
        print("   ‚úÖ IMPLEMENTA√á√ÉO VALIDADA")
        print("   ‚úÖ Filtros de qualidade fundamentalista: FUNCIONANDO")
        print("   ‚úÖ ROE consistente > 15%: IMPLEMENTADO")
        print("   ‚úÖ Crescimento sustent√°vel: IMPLEMENTADO")
        print("   ‚úÖ Endividamento controlado: IMPLEMENTADO") 
        print("   ‚úÖ Margens est√°veis: IMPLEMENTADO")
        print("   ‚úÖ Red flags para empresas problem√°ticas: FUNCIONANDO")
        print("   ‚úÖ Sistema de recomenda√ß√µes: OPERACIONAL")
        print("   ‚úÖ Todos os crit√©rios de aceita√ß√£o atendidos")
        print(f"\nüéä FASE 2 PASSO 2 COMPLETAMENTE FINALIZADA!")
        print(f"üöÄ PR√ìXIMO PASSO: Implementar FundamentalAnalyzerAgent (Passo 3)")
        print(f"üìÅ Componentes validados:")
        print(f"   ‚úÖ agents/analyzers/scoring_engine.py")
        print(f"   ‚úÖ agents/analyzers/sector_comparator.py") 
        print(f"   ‚úÖ agents/analyzers/quality_filters.py")
    else:
        print("   ‚ùå IMPLEMENTA√á√ÉO INCOMPLETA")
        print("   üîß Revisar e corrigir problemas identificados")
        print("   ‚ö†Ô∏è  N√£o prosseguir at√© resolver os issues")
    
    print("\n" + "=" * 80)
    
    return overall_success


if __name__ == "__main__":
    try:
        success = main()
        if success:
            print("üéâ VALIDA√á√ÉO CONCLU√çDA COM SUCESSO!")
            print("‚úÖ Quality Filters est√° implementado e funcionando corretamente.")
            print("üèÜ Fase 2 Passo 2.3 VALIDADA - Sistema de Crit√©rios de Qualidade COMPLETO!")
            print("üöÄ Pronto para avan√ßar para o Passo 3 da Fase 2.")
            print("\nüéØ PR√ìXIMOS PASSOS RECOMENDADOS:")
            print("   1. Implementar FundamentalAnalyzerAgent (Passo 3.1)")
            print("   2. Pipeline de processamento integrado (Passo 3.2)")
            print("   3. Sistema de justificativas autom√°ticas (Passo 3.3)")
            print("\nüìä RESUMO DA FASE 2 PASSO 2:")
            print("   ‚úÖ Scoring Engine (Passo 2.1): COMPLETO")
            print("   ‚úÖ Sector Comparator (Passo 2.2): COMPLETO")
            print("   ‚úÖ Quality Filters (Passo 2.3): COMPLETO")
            print("\nüéä FASE 2 PASSO 2 - 100% IMPLEMENTADA!")
            sys.exit(0)
        else:
            print("‚ö†Ô∏è  VALIDA√á√ÉO CONCLU√çDA COM PROBLEMAS!")
            print("üîß Revisar e corrigir os issues identificados.")
            print("‚ùå N√£o prosseguir at√© resolver os problemas.")
            print("\nüîç A√á√ïES RECOMENDADAS:")
            print("   1. Verificar implementa√ß√£o dos filtros obrigat√≥rios")
            print("   2. Validar sistema de red flags")
            print("   3. Testar gera√ß√£o de recomenda√ß√µes")
            print("   4. Executar testes individuais para debugging")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  Valida√ß√£o interrompida pelo usu√°rio.")
        sys.exit(2)
        
    except Exception as e:
        print(f"\nüí• ERRO CR√çTICO na valida√ß√£o: {e}")
        traceback.print_exc()
        print("\nüîß SUGEST√ïES PARA RESOLVER:")
        print("   1. Verificar se quality_filters.py existe no diret√≥rio correto")
        print("   2. Verificar se todas as depend√™ncias est√£o instaladas")
        print("   3. Verificar se o PYTHONPATH est√° configurado corretamente")
        print("   4. Executar o teste do quality_filters.py diretamente primeiro")
        sys.exit(3)